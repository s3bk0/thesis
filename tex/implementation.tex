On basis of the preceding theory a full simulation of acoustic wave propagation
through multilayer structures was developed. This will be
described in more detail in the following aiming to provide a short
introduction into code structure and functionality. Arisen challenges and their
solution will be presented afterwards.

\section{Code Structure and Functionality}
The main components of the project are represented by the three python modules
\texttt{dbr.py}, \texttt{materials.py} and \texttt{plotfunctions.py} to
organise written methods by purpose.

\texttt{materials.py} contains elastic parameters of materials that were
considered for usage in a reflector structure. Each entry is a python function
that returns density $\rho$ and elastic constants $\lambda$ and $\mu$. Most
databases accessible through the internet contain different elastic constants
like Young`s Modulus or Poisson´s ratio, so that those are converted with help
of a formula table as in \cite[30]{kundu2012ultrasonic} \todo{Formeln in
    Theorieteil?}. The exact materials and their sources are listed in table
\todo{reference to material parameters}

The file \texttt{dbr.py} contains the most important simulation tools. Those
functions are structured in two classes, \texttt{Reflector} and \texttt{Layer}
to reduce the number of parameters to be passed to the next method.

The main idea for the \texttt{Layer} class is to wrap the important material
parameters $\lambda$, $\mu$ and $\rho$ passed from a material parameter
function and to convert them internally to sound velocities $c_i$ and elastic
tensor. In addition, each object stores its thickness and material name. The
latter is useful for fast identification of the layer material and debugging
outputs.
Also, it contains several methods for calculation of Layer specific
quantities. One of those quantities is \texttt{getConditionMatrix()} which
assembles the condition matrix $\uuline{M}_n$ for a given incident angle
$\theta$ and frequency $\omega$. In the process, the layer specific wave vector
$\uline{k}_i$ is calculated by \texttt{Layer.getK()} for every mode from
incident angle and frequency. The phase velocities are accessed from the
object. Calculation of polarisation vectors (\texttt{getPolarisations()}) and
strain tensor (\texttt{getStrain()}) follows the same principle. The functions
\texttt{Intensity()} implementing equation \ref{eq:generalIntensity} and
\texttt{getPropagationMatrix()} implementing $\uuline{P}_n$ from equation
\ref{eq:PmatTMM} support the later mentioned methods from
\texttt{Reflector}.

To construct a layer structure that can be evaluated by the simulation tools of
\texttt{Reflector}, those \texttt{Layer} objects can be assembled in a list,
which indicates the order of Layers in the reflector structure. Together with
the defined thicknesses of each \texttt{Layer} object this forms an unambiguous
representation of a physical layer structure.

This list of \texttt{Layer} objects is then passed to the constructor of a
\texttt{Reflector} object and stored as deep copy of the initial list to avoid
bugs through references to the same object. Besides, the layer thicknesses are
extracted and stored internally in a separate list which is used exclusively
over the object stored thicknesses. The first and the last given
layer are assumed to embed the remaining layers, so that their thickness
defined in the \texttt{Layer} object has no meaning. Thus the thicknesses of
first and last layer are set to $0$ in \texttt{Reflector.\_\_init\_\_()} for
convenience in the simulation functions. The thickness configuration can be
changed with \texttt{setThicknesses()} and a full text representation of the
current configuration can be generated with \texttt{info()}.

\subsection{Algorithms and their Scope of Application }
There are four methods implemented to calculate the transmittivity function
$\mathcal{T}_i(\omega, \theta)$ differing in numerical stability and speed.
Those are \ttt{TransferMethod()} and \ttt{TransferMethodMP()}, which implement
the Transfer Matrix Method and on the other side \ttt{LSEMethod()} and
\ttt{SingleLSEMethod()}, which implement the described LSE method. All of those
methods take the same kind of parameters, which are frequency $\omega$,
incident angle $\theta$ and the coefficient vector of the initial wave
$\uline{t}_0$. The returned values are the transmission and reflection
coefficients $\uline{t}_N$ and $\uline{r}_0$ as well as transmittivity
$\mathcal{T}$ and reflectivity $\mathcal{R}$. The last two quantities
are evaluated by calling \ttt{Reflector.Intensities()} in turn relies on
the layer specific intensites from \ttt{Layer.Intensity()}.

To explain the coexistence of the methods, it is helpful to describe and
analyse them in the order of their development. The challenge here was not to
get a working implementation, but an implementation that is able to produce
valid results in convenient time for the problem described in the introduction.

One important tool for validating the obtained transmittivity values is the
sanity check. Each of these methods is checked for energy conservation by
evaluating the
validity of $\mathcal{R}+\mathcal{T}=1$, the sum of reflectivity $\mathcal{R}$
and transmittivity $\mathcal{T}$ which was discussed in section
\ref{sec:sanitycheck}. It offers a fast test for reasonable
results. However, it can not exclude all kinds of errors so that additional
validation against known cases will be provided.

The first attempt was \ttt{TransferMethod()}. The TMM offers the most promising
properties with regard to computation time for large systems, because existing
matrix multiplication algorithms as implemented in the \ttt{numpy} package can
be used and the addition of layers to the problem only increases the
computation time linearly. The latter becomes apparent when considering
equation \ref{eq:Scomposition}.

Although the implemented algorithm is fast as expected and is able to pass the
sanity check, a significant limitation occurs for layer structures with more
than 6 interfaces and frequencies over a few GHz. The sanity of the values of
such configurations begins to decay for large angles. Large regions in angle
frequency space establish, where the resulting values are covered by a strong
noise leading to values of almost diverging magnitude. Examples of that
behaviour are shown in the appendix.

It is assumed that this is caused during calculation of very large and very
small values with limited precision. \todo[color=LightGreen]{more specific
    explanation?}
This especially occurs in the propagation matrix $\uuline{P}_n$, which is
responsible for the propagation of the coefficients through a layer. It
contains
both large and small
values in the case of evanescent waves. The wave vector adopts
a negative complex part so that the lower diagonal entries increase
exponentially with layer thickness while the upper diagonal entries decrease
with layer thickness.

The effect of the nature of $\uuline{P}$ was investigated by analysing
the continuity in $\theta$ of matrix entries with a debugging tool. The
intention was to find the operation that causes the most numerical instability,
which shows in non continuous functionality of the result.

However, it was found that the mere composition to the complete transfer
matrix $\uuline{S}$ is less relevant for that effect than the final calculation
of the coefficients in equations \ref{eq:TMMcoeffsr} and \ref{eq:TMMcoeffst}.
These are unfortunately essential to the Transfer Matrix Method.

As other explanations over the source of the numerical instabilities could not
be verified and after several unsuccessful attempts of improving numerical
stability, the lse method was considered. It represents the rather heuristic
approach to solve the system of equations in one step with the benefit, that
the exponentials with magnifying exponential can be reformulated as attenuating
exponential functions. Therefore, the numerical issues could be improved in a
manner that the required computations can be undertaken successfully.

However, this method has other disadvantages. Firstly, the time complexity is
no longer linear in the number of layers. % but cubic for matrix inversion
The method is significantly slower for small problems which makes large
problems much more time consuming than with the TMM.
Another limitation is given by
the \ttt{numpy} focused coding style, where python loops are avoided by
initialising arrays and exploiting faster matrix operations. Here the loop over
arrays of initial angles $\theta$ and the related frequencies $\omega$ was
implemented by stacking the matrices and vectors for a single value pair along
additional dimensions. As a result, the computation transmittivity values for
several hundreds of frequencies with several hundreds of angles each at one
time can require more storage than a typical RAM can offer.

Another approach was to use sparse matrices
with the package \ttt{sparse} which is compatible with \ttt{numpy} and
implements much more efficient storage of matrices with many zero valued
elements. Although the present matrices fullfil this criterion, the assembly of
those matrices from numpy dense matrices prooved too slow in comparison to the
gained speed. This is possibly related to the circumstance, that the module
wraps the computational methods of \ttt{scipy.sparse.linalg} which only uses
two-dimensional sparse matrices.

For this reason, the method \ttt{SingleLSEMethod()} was created as linearised
method using python loops. In each iteration, it passes a single angle and
frequency to \ttt{LSEMethod()}. For that case it was also optimised by using
the sparse system solver \ttt{spsolve()} from \ttt{scipy.sparse.linalg} which
improves the performance further.

As the LSE Method also encounters numerical problems for larger structures a
fourth attempt was made by using the module \ttt{mpmath}. It provides
types with arbitrary numerical precision. A full implementation of the Transfer
Matrix Method with \ttt{mpmath} is given by \ttt{TransferMethodMP()} and
several submethods ending with \ttt{MP}. This was done by Tobias Hangleiter in
analogy to the existing TMM implementation.
The \ttt{mpmath} approach is able to deliver numerically stable results as
expected. However, the computation time is significantly higher than for all
other methods, so that it is only used in cases, where the other methods fail.

In addition, another optimisation can be implemented. All these algorithms rely
on several subroutines like for example \ttt{Layer.getConditionMatrix()}, which
calculates the matrix $\uuline{M}_n$ from equation \ref{eq:defSn}. In this and
other cases, the function is called several times with the same arguments due
to the fact, that the propagating angles in each Layer are equal in each Layer
of the same type. For this reason, the results of these subroutines are cached.
As conventional caching decorators require the function parameters to be
hashable and this does not apply for \ttt{numpy} arrays, caching was
implemented by hand. The essential part of this are the hash function
\ttt{Hash()} which converts an arbitrary number of parameters to a hashable
tuple. This hash is then used as key in a dictionary for the results of the
hashed function. For each cached function there is such a dictionary stored in
either \ttt{Reflector} or \ttt{Layer}.

% The concrete implementation is as follows. \ttt{TransferMethod()} called with
% arrays of circular frequencies $\omega$, incident angles $\theta$ and the
% coefficient vector $t_0$ passes those parameters first to
% \ttt{getTotalTransfermatrix()}. This function calculates the $\uuline{S}$
% matrix for the entire system as in equation \ref{eq:Scomposition}. The function
% iterates in a python \ttt{for}-loop over all defined interfaces. In each
% iteration $n$, the transmitted angles from the previous interface
% $\theta_{n-1,i}$
% are used as incident angles on the current interface $n$. Those are needed to
% calculate the wave vectors and the propagation matrix $\uuline{P}_n$ with
% \ttt{getK()} and \ttt{getPropagationMatrix()} called on the upper Layer object.
% $\uuline{S}_n$ is also calculated from $\theta_n$ and $\omega$ with
% \ttt{TransferMatrix()}. Those two matrices, $\uuline{S}_n$ and $\uuline{P}_n$
% are then multiplied to the evolving total S-matrix of the previous iteration 
% $\uuline{S}_{n-1}^\prime$ as
% \begin{equation}
%     \uuline{S}_n^\prime = \uuline{P}_n \cdot \uuline{S}_n \cdot \uuline{S}_{n-1}
% \end{equation}

%BraggFreq

\subsection{Plots and Scripts for Evaluation}
In order to evaluate the total heat transfer, these methods are used to
calculate an array of transmittivities over all angles
$\theta\in[0^{\circ},90^{\circ}]$ and over all frequencies
$\omega \in (0\si{s^{-1}}, 30\cdot 10^{11}\si{s^{-1}}] $. The integral
\ref{eq:totalheatflow} is then evaluated first by integrating over the angles
which is done by \ttt{Reflector.spectralTransmission()} using the method
\ttt{numpy.trapz()}. The weighting factor $\cos \theta$ is also considered so
that the resulting values represent spectral transmittivity in z-direction.
The total heat flow is calculated with \ttt{transmittedPower()} by evaluating
the described integrant at the same frequencies as the spectral transmittivity
and integrating it analogously to the angles. \todo{mention $\Delta P$}

The intermediate results of this calculation may be of interest as well. For
this purpose, \ttt{plotfunctions.py} provides a number of plot functions and
scripts that were also used to generate the plots in the later course of this
thesis. The first important plot funtion is \ttt{plotAngluarTransmission()}.
It produces three subplots. In the first, the absolute values of the reflection
coefficients are shown which represent the reflected amplitudes. The plot below
does the same for the transmission coefficients. In the lowermost plot the
resulting transmittivity and reflectivity are shown as functions of
incident angle for a fixed frequency. Also their sum is displayed as proof of 
correctness of the values. This can be viewed for example in figure
\todo{Angular Plot reference}.

In comparison to that, \ttt{plotOverview()} accepts transmittivity values from
a region in angle-frequency space as two-dimensional array and is able to
provide a three-part plot as in figure \todo{overview plot reference}. Here the
upper left field represents a color plot of the sanity of the transmittivity
over frequency and angle axis. Dots coded as $1$ denote that the transmittivity
at the corresponding angle and frequency was calculated correctly. At the
right, the transmittivity values are represented directly in a similar plot.
Those two plots help to understand the regions of numerical instabilites but
also the behaviour of transparent regions of the reflector under angle or
frequency variation. The lower plot, the spectral radiance transmitted through
the reflector in comparison to the incident radiance. A textbox also shows the
results of the integration over those curves and the ratio of transmitted
power.
For each plot a boolean parameter is passed to the function to enable or
disable the appearance of each plot in the output.

These plot functions also exist in form of a script like function, that
generates the necessary transmission values by itself and directly provide the
output as plot.

Ín addition to these evaluation plots, there is an additional utility function
called
\ttt{EffectivityOverThickness()}. It is an attempt to automatise the
optimisation process that will be described later. The method calculates the
ratio of transmitted power as in \ttt{transmittedPower()} for a reflector with
two different materials with repeating thicknesses. The output is a matrix,
where thickness of layer 1 varies along the first axis and the thickness of
layer 2 varies along the second axis. This matrix is again represented as
colorplot. This plot was not used here as it is very time consuming to compute
and has only limited significance.

% \subsection{Example Workflow}
% As a practical summary of the previous description, a short 
\todo[color=LightGreen]{ Example Workflow still advantageous?}
cite